## Группа 3
[Ксения Милючихина](https://github.com/horomiii) ——
[Александр Годелашвили](https://github.com/tumpaksewu) ——
[Артём Бабаев](https://github.com/ArtemInDs)

<img src="https://lejdiprifti.com/wp-content/uploads/2024/01/house-price-prediction-1920x1080.webp" width="500">

<br/><br/>

Изначальный скор на Kaggle: 0.133</br>
Финальный скор: 0.1278 </br>
</br></br>
Что было сделано:</br>
1. EDA (разведочный анализ данных)</br>
Установили размерность, пропуски, распределение фичей</br>
Удалены несколько выбросов данных</br>
Нарисовали: scatteplot-ы зависимостей всех фичей к таргету, histplot-ы распределения всех фичей (здесь можно прикрепить изображения которые выше)</br>
2. Заполнение NaN:</br>
Заполнили пропуски в зависимости от значения: для подвалов, бассейнов итд сделали специальный imputer, проставляющий категорию "нет"</br>
3. Feature engineering:</br>
Созданы такие признаки, как "есть бассейн", "есть веранда" и др.</br>
Схлопнуты признаки квадратуры в общие</br>
4. Пайплайн:</br>
Пайплайн реализован через связку imputer > encoder > scaler > extra imputer</br>
Использованы 4 энкодера, в зависимости от типа переменной: Ordinal, Binary, OHE, Target</br>
5. Выбор моделей</br>
Попробовали: Random Forest, XGBoost, LGBM, Catboost</br>
Натренировали хороший XGBoost, но он был слишком чувствителен к датасету, получилось переобучение</br>
Использовали Optuna (4 различных подхода, все с кросс-валидацией) для подбора оптимального CatBoost</br>
Также сделали бутстреп train.csv, проверили на нем</br>
Наилучшие результату по итогу показал осторожно натюненный CatBoost</br>
6. Feature selection</br>
После первых результатов, произвели попытку исправления мультиколлинеарности и удаления зависимых / ненужных фичей</br>
Кастомная по определению корреляции</br>
Lasso (с подбором alpha через Optuna)</br>
f-Test</br>
PCA</br>
Feature importance (на всех пермутациях энкодинга для лучшей точности) для CatBoost и XGB</br>
SHAP values</br>
VIF</br>
Далее ручное сравнение и гипотезы. По итогу пытались дропать около 10 разных комбинаций признаков, дало отрицательный результат.</br>
7. Финальный стек для инференса:</br>
Бленд-модель:</br>
Catboost / XGB / Lasso</br> 
0.6 / 0.2 / 0.2</br>
